---
supplementary: Supplementary:hamm16-supp.pdf
title: Learning privately from multiparty data
abstract: Learning a classifier from private data distributed across multiple parties
  is an important problem that has many potential applications. How can we build an
  accurate and differentially private global classifier by combining locally-trained
  classifiers from different parties, without access to any party’s private data?
  We propose to transfer the “knowledge” of the local classifier ensemble by first
  creating labeled data from auxiliary unlabeled data, and then train a global differentially
  private classifier. We show that majority voting is too sensitive and therefore
  propose a new risk weighted by class probabilities estimated from the ensemble.
  Relative to a non-private solution, our private solution has a generalization error
  bounded by O(ε^-2 M^-2). This allows strong privacy without performance loss when
  the number of participating parties M is large, such as in crowdsensing applications.
  We demonstrate the performance of our framework with realistic tasks of activity
  recognition, network intrusion detection, and malicious URL detection.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: hamm16
month: 0
tex_title: Learning privately from multiparty data
firstpage: 555
lastpage: 563
page: 555-563
sections: 
author:
- given: Jihun
  family: Hamm
- given: Yingjun
  family: Cao
- given: Mikhail
  family: Belkin
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/hamm16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
