---
title: Meta–Gradient Boosted Decision Tree Model for Weight and Target Learning
abstract: Labeled training data is an essential part of any supervised machine learning
  framework. In practice, there is a trade-off between the quality of a label and
  its cost. In this paper, we consider a problem of learning to rank on a large-scale
  dataset with low-quality relevance labels aiming at maximizing the quality of a
  trained ranker on a small validation dataset with high-quality ground truth relevance
  labels. Motivated by the classical Gauss-Markov theorem for the linear regression
  problem, we formulate the problems of (1) reweighting training instances and (2)
  remapping learning targets. We propose meta–gradient decision tree learning framework
  for optimizing weight and target functions by applying gradient-based hyperparameter
  optimization. Experiments on a large-scale real-world dataset demonstrate that we
  can significantly improve state-of-the-art machine-learning algorithms by incorporating
  our framework.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: ustinovskiy16
month: 0
tex_title: Meta--Gradient Boosted Decision Tree Model for Weight and Target Learning
firstpage: 2692
lastpage: 2701
page: 2692-2701
sections: 
author:
- given: Yury
  family: Ustinovskiy
- given: Valentina
  family: Fedorova
- given: Gleb
  family: Gusev
- given: Pavel
  family: Serdyukov
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/ustinovskiy16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
