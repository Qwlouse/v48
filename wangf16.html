<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Dueling Network Architectures for Deep Reinforcement Learning | ICML 2016 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Dueling Network Architectures for Deep Reinforcement Learning">

  <meta name="citation_author" content="Wang, Ziyu">

  <meta name="citation_author" content="Schaul, Tom">

  <meta name="citation_author" content="Hessel, Matteo">

  <meta name="citation_author" content="Hasselt, Hado van">

  <meta name="citation_author" content="Lanctot, Marc">

  <meta name="citation_author" content="Freitas, Nando de">

<meta name="citation_publication_date" content="2016">
<meta name="citation_conference_title" content="Proceedings of The 33rd International Conference on Machine Learning">
<meta name="citation_firstpage" content="1995">
<meta name="citation_lastpage" content="2003">
<meta name="citation_pdf_url" content="http://jmlr.org/proceedings/papers/v48/wangf16.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Dueling Network Architectures for Deep Reinforcement Learning</h1>

	<div id="authors">
	
		Ziyu Wang,
	
		Tom Schaul,
	
		Matteo Hessel,
	
		Hado van Hasselt,
	
		Marc Lanctot,
	
		Nando de Freitas
	<br />
	</div>
	<div id="info">
		Proceedings of The 33rd International Conference on Machine Learning,
		pp. 1995â€“2003, 2016
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		In recent years there have been many successes of using deep representations in reinforcement learning. Still, many of these applications use conventional architectures, such as convolutional networks, LSTMs, or auto-encoders. In this paper, we present a new neural network architecture for model-free reinforcement learning. Our dueling network represents two separate estimators: one for the state value function and one for the state-dependent action advantage function. The main benefit of this factoring is to generalize learning across actions without imposing any change to the underlying reinforcement learning algorithm. Our results show that this architecture leads to better policy evaluation in the presence of many similar-valued actions. Moreover, the dueling architecture enables our RL agent to outperform the state-of-the-art on the Atari 2600 domain.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="wangf16.pdf">Download PDF</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
