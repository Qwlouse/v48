---
title: Low-Rank Matrix Approximation with Stability
abstract: Low-rank matrix approximation has been widely adopted in machine learning
  applications with sparse data, such as recommender systems. However, the sparsity
  of the data, incomplete and noisy, introduces challenges to the algorithm stability
  â€“ small changes in the training data may significantly change the models. As a result,
  existing low-rank matrix approximation solutions yield low generalization performance,
  exhibiting high error variance on the training dataset, and minimizing the training
  error may not guarantee error reduction on the testing dataset. In this paper, we
  investigate the algorithm stability problem of low-rank matrix approximations. We
  present a new algorithm design framework, which (1) introduces new optimization
  objectives to guide stable matrix approximation algorithm design, and (2) solves
  the optimization problem to obtain stable low-rank approximation solutions with
  good generalization performance. Experimental results on real-world datasets demonstrate
  that the proposed work can achieve better prediction accuracy compared with both
  state-of-the-art low-rank matrix approximation methods and ensemble methods in recommendation
  task.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: lib16
month: 0
tex_title: Low-Rank Matrix Approximation with Stability
firstpage: 295
lastpage: 303
page: 295-303
order: 295
cycles: false
author:
- given: Dongsheng
  family: Li
- given: Chao
  family: Chen
- given: Qin
  family: Lv
- given: Junchi
  family: Yan
- given: Li
  family: Shang
- given: Stephen
  family: Chu
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/lib16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
