---
supplementary: http://proceedings.mlr.press/v48/wange16-supp.pdf
title: 'No penalty no tears: Least squares in high-dimensional linear models'
abstract: Ordinary least squares (OLS) is the default method for fitting linear models,
  but is not applicable for problems with dimensionality larger than the sample size.
  For these problems, we advocate the use of a generalized version of OLS motivated
  by ridge regression, and propose two novel three-step algorithms involving least
  squares fitting and hard thresholding. The algorithms are methodologically simple
  to understand intuitively, computationally easy to implement efficiently, and theoretically
  appealing for choosing models consistently. Numerical exercises comparing our methods
  with penalization-based approaches in simulations and data analyses illustrate the
  great potential of the proposed algorithms.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: wange16
month: 0
tex_title: 'No penalty no tears: Least squares in high-dimensional linear models'
firstpage: 1814
lastpage: 1822
page: 1814-1822
order: 1814
cycles: false
author:
- given: Xiangyu
  family: Wang
- given: David
  family: Dunson
- given: Chenlei
  family: Leng
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/wange16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
