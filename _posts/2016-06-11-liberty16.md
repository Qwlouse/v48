---
title: Stratified Sampling Meets Machine Learning
abstract: This paper solves a specialized regression problem to obtain sampling probabilities
  for records in databases. The goal is to sample a small set of records over which
  evaluating aggregate queries can be done both efficiently and accurately. We provide
  a principled and provable solution for this problem; it is parameterless and requires
  no data insights. Unlike standard regression problems, the loss is inversely proportional
  to the regressed-to values. Moreover, a cost zero solution always exists and can
  only be excluded by hard budget constraints. A unique form of regularization is
  also needed. We provide an efficient and simple regularized Empirical Risk Minimization
  (ERM) algorithm along with a theoretical generalization result. Our extensive experimental
  results significantly improve over both uniform sampling and standard stratified
  sampling which are de-facto the industry standards.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: liberty16
month: 0
firstpage: 2320
lastpage: 2329
page: 2320-2329
sections: 
author:
- given: Edo
  family: Liberty
- given: Kevin
  family: Lang
- given: Konstantin
  family: Shmakov
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/liberty16/liberty16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
