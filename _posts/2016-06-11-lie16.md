---
supplementary: Supplementary:lie16-supp.pdf
title: Learning to Generate with Memory
abstract: Memory units have been widely used to enrich the capabilities of deep networks
  on capturing long-term dependencies in reasoning and prediction tasks, but little
  investigation exists on deep generative models (DGMs) which are good at inferring
  high-level invariant representations from unlabeled data. This paper presents a
  deep generative model with a possibly large external memory and an attention mechanism
  to capture the local detail information that is often lost in the bottom-up abstraction
  process in representation learning. By adopting a smooth attention model, the whole
  network is trained end-to-end by optimizing a variational bound of data likelihood
  via auto-encoding variational Bayesian methods, where an asymmetric recognition
  network is learnt jointly to infer high-level invariant representations. The asymmetric
  architecture can reduce the competition between bottom-up invariant feature extraction
  and top-down generation of instance details. Our experiments on several datasets
  demonstrate that memory can significantly boost the performance of DGMs on various
  tasks, including density estimation, image generation, and missing value imputation,
  and DGMs with memory can achieve state-of-the-art quantitative results.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: lie16
month: 0
firstpage: 1177
lastpage: 1186
page: 1177-1186
sections: 
author:
- given: Chongxuan
  family: Li
- given: Jun
  family: Zhu
- given: Bo
  family: Zhang
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/lie16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
