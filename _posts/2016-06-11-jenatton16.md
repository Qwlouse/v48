---
title: Adaptive Algorithms for Online Convex Optimization with Long-term Constraints
abstract: We present an adaptive online gradient descent algorithm to solve online
  convex optimization problems with long-term constraints, which are constraints that
  need to be satisfied when accumulated over a finite number of rounds T, but can
  be violated in intermediate rounds. For some user-defined trade-off parameter βin
  (0, 1), the proposed algorithm achieves cumulative regret bounds of O(T^maxβ,1_β)
  and O(T^1_β/2), respectively for the loss and the constraint violations. Our results
  hold for convex losses, can handle arbitrary convex constraints and rely on a single
  computationally efficient algorithm. Our contributions improve over the best known
  cumulative regret bounds of Mahdavi et al. (2012), which are respectively O(T^1/2)
  and O(T^3/4) for general convex domains, and respectively O(T^2/3) and O(T^2/3)
  when the domain is further restricted to be a polyhedral set. We supplement the
  analysis with experiments validating the performance of our algorithm in practice.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: jenatton16
month: 0
tex_title: Adaptive Algorithms for Online Convex Optimization with Long-term Constraints
firstpage: 402
lastpage: 411
page: 402-411
order: 402
cycles: false
author:
- given: Rodolphe
  family: Jenatton
- given: Jim
  family: Huang
- given: Cedric
  family: Archambeau
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/jenatton16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
