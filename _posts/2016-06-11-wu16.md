---
supplementary: Supplementary:wu16-supp.zip
title: Conservative Bandits
abstract: We study a novel multi-armed bandit problem that models the challenge faced
  by a company wishing to explore new strategies to maximize revenue whilst simultaneously
  maintaining their revenue above a fixed baseline, uniformly over time. While previous
  work addressed the problem under the weaker requirement of maintaining the revenue
  constraint only at a given fixed time in the future, the design of those algorithms
  makes them unsuitable under the more stringent constraints. We consider both the
  stochastic and the adversarial settings, where we propose natural yet novel strategies
  and analyze the price for maintaining the constraints. Amongst other things, we
  prove both high probability and expectation bounds on the regret, while we also
  consider both the problem of maintaining the constraints with high probability or
  expectation. For the adversarial setting the price of maintaining the constraint
  appears to be higher, at least for the algorithm considered. A lower bound is given
  showing that the algorithm for the stochastic setting is almost optimal. Empirical
  results obtained in synthetic environments complement our theoretical findings.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: wu16
month: 0
firstpage: 1254
lastpage: 1262
page: 1254-1262
sections: 
author:
- given: Yifan
  family: Wu
- given: Roshan
  family: Shariff
- given: Tor
  family: Lattimore
- given: Csaba
  family: Szepesvari
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/wu16/wu16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
