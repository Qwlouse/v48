---
supplementary: Supplementary:ranganath16-supp.pdf
title: Hierarchical Variational Models
abstract: 'Black box variational inference allows researchers to easily prototype
  and evaluate an array of models. Recent advances allow such algorithms to scale
  to high dimensions. However, a central question remains: How to specify an expressive
  variational distribution that maintains efficient computation? To address this,
  we develop hierarchical variational models (HVMs). HVMs augment a variational approximation
  with a prior on its parameters, which allows it to capture complex structure for
  both discrete and continuous latent variables. The algorithm we develop is black
  box, can be used for any HVM, and has the same computational efficiency as the original
  approximation. We study HVMs on a variety of deep discrete latent variable models.
  HVMs generalize other expressive variational distributions and maintains higher
  fidelity to the posterior.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: ranganath16
month: 0
firstpage: 324
lastpage: 333
page: 324-333
sections: 
author:
- given: Rajesh
  family: Ranganath
- given: Dustin
  family: Tran
- given: David
  family: Blei
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/ranganath16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
