---
supplementary: Supplementary:reed16-supp.zip
title: Generative Adversarial Text to Image Synthesis
abstract: Automatic synthesis of realistic images from text would be interesting and
  useful, but current AI systems are still far from this goal. However, in recent
  years generic and powerful recurrent neural network architectures have been developed
  to learn discriminative text feature representations. Meanwhile, deep convolutional
  generative adversarial networks (GANs) have begun to generate highly compelling
  images of specific categories such as faces, album covers, room interiors and flowers.
  In this work, we develop a novel deep architecture and GAN formulation to effectively
  bridge these advances in text and image modeling, translating visual concepts from
  characters to pixels. We demonstrate the capability of our model to generate plausible
  images of birds and flowers from detailed text descriptions.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: reed16
month: 0
firstpage: 1060
lastpage: 1069
page: 1060-1069
sections: 
author:
- given: Scott
  family: Reed
- given: Zeynep
  family: Akata
- given: Xinchen
  family: Yan
- given: Lajanugen
  family: Logeswaran
- given: Bernt
  family: Schiele
- given: Honglak
  family: Lee
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/reed16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
