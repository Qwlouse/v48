---
supplementary: Supplementary:thomasb16-supp.pdf
title: Energetic Natural Gradient Descent
abstract: We propose a new class of algorithms for minimizing or maximizing functions
  of parametric probabilistic models. These new algorithms are natural gradient algorithms
  that leverage more information than prior methods by using a new metric tensor in
  place of the commonly used Fisher information matrix. This new metric tensor is
  derived by computing directions of steepest ascent where the distance between distributions
  is measured using an approximation of energy distance (as opposed to Kullback-Leibler
  divergence, which produces the Fisher information matrix), and so we refer to our
  new ascent direction as the energetic natural gradient.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: thomasb16
month: 0
firstpage: 2887
lastpage: 2895
page: 2887-2895
sections: 
author:
- given: Philip
  family: Thomas
- given: Bruno Castro
  family: Silva
- given: Christoph
  family: Dann
- given: Emma
  family: Brunskill
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/thomasb16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
