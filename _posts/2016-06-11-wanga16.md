---
title: Analysis of Deep Neural Networks with Extended Data Jacobian Matrix
abstract: Deep neural networks have achieved great successes on various machine learning
  tasks, however, there are many open fundamental questions to be answered. In this
  paper, we tackle the problem of quantifying the quality of learned wights of different
  networks with possibly different architectures, going beyond considering the final
  classification error as the only metric. We introduce \emphExtended Data Jacobian
  Matrix to help analyze properties of networks of various structures, finding that,
  the spectrum of the extended data jacobian matrix is a strong discriminating factor
  for networks of different structures and performance. Based on such observation,
  we propose a novel regularization method, which manages to improve the network performance
  comparably to dropout, which in turn verifies the observation.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: wanga16
month: 0
tex_title: Analysis of Deep Neural Networks with Extended Data Jacobian Matrix
firstpage: 718
lastpage: 726
page: 718-726
sections: 
author:
- given: Shengjie
  family: Wang
- given: Abdel-rahman
  family: Mohamed
- given: Rich
  family: Caruana
- given: Jeff
  family: Bilmes
- given: Matthai
  family: Plilipose
- given: Matthew
  family: Richardson
- given: Krzysztof
  family: Geras
- given: Gregor
  family: Urban
- given: Ozlem
  family: Aslan
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/wanga16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
