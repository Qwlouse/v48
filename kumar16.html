<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Ask Me Anything: Dynamic Memory Networks for Natural Language Processing | ICML 2016 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Ask Me Anything: Dynamic Memory Networks for Natural Language Processing">

  <meta name="citation_author" content="Kumar, Ankit">

  <meta name="citation_author" content="Irsoy, Ozan">

  <meta name="citation_author" content="Ondruska, Peter">

  <meta name="citation_author" content="Iyyer, Mohit">

  <meta name="citation_author" content="Bradbury, James">

  <meta name="citation_author" content="Gulrajani, Ishaan">

  <meta name="citation_author" content="Zhong, Victor">

  <meta name="citation_author" content="Paulus, Romain">

  <meta name="citation_author" content="Socher, Richard">

<meta name="citation_publication_date" content="2016">
<meta name="citation_conference_title" content="Proceedings of The 33rd International Conference on Machine Learning">
<meta name="citation_firstpage" content="1378">
<meta name="citation_lastpage" content="1387">
<meta name="citation_pdf_url" content="http://jmlr.org/proceedings/papers/v48/kumar16.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Ask Me Anything: Dynamic Memory Networks for Natural Language Processing</h1>

	<div id="authors">
	
		Ankit Kumar,
	
		Ozan Irsoy,
	
		Peter Ondruska,
	
		Mohit Iyyer,
	
		James Bradbury,
	
		Ishaan Gulrajani,
	
		Victor Zhong,
	
		Romain Paulus,
	
		Richard Socher
	<br />
	</div>
	<div id="info">
		Proceedings of The 33rd International Conference on Machine Learning,
		pp. 1378–1387, 2016
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		Most tasks in natural language processing can be cast into question answering (QA) problems over language input. We introduce the dynamic memory network (DMN), a neural network architecture which processes input sequences and questions, forms episodic memories, and generates relevant answers. Questions trigger an iterative attention process which allows the model to condition its attention on the inputs and the result of previous iterations. These results are then reasoned over in a hierarchical recurrent sequence model to generate answers. The DMN can be trained end-to-end and obtains state-of-the-art results on several types of tasks and datasets: question answering (Facebook’s bAbI dataset), text classification for sentiment analysis (Stanford Sentiment Treebank) and sequence modeling for part-of-speech tagging (WSJ-PTB). The training for these different tasks relies exclusively on trained word vector representations and input-question-answer triplets.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="kumar16.pdf">Download PDF</a></li>
			
			<li><a href="kumar16-supp.pdf">Supplementary (PDF)</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
