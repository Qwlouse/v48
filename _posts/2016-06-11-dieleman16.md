---
title: Exploiting Cyclic Symmetry in Convolutional Neural Networks
abstract: Many classes of images exhibit rotational symmetry. Convolutional neural
  networks are sometimes trained using data augmentation to exploit this, but they
  are still required to learn the rotation equivariance properties from the data.
  Encoding these properties into the network architecture, as we are already used
  to doing for translation equivariance by using convolutional layers, could result
  in a more efficient use of the parameter budget by relieving the model from learning
  them. We introduce four operations which can be inserted into neural network models
  as layers, and which can be combined to make these models partially equivariant
  to rotations. They also enable parameter sharing across different orientations.
  We evaluate the effect of these architectural modifications on three datasets which
  exhibit rotational symmetry and demonstrate improved performance with smaller models.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: dieleman16
month: 0
tex_title: Exploiting Cyclic Symmetry in Convolutional Neural Networks
firstpage: 1889
lastpage: 1898
page: 1889-1898
order: 1889
cycles: false
author:
- given: Sander
  family: Dieleman
- given: Jeffrey De
  family: Fauw
- given: Koray
  family: Kavukcuoglu
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/dieleman16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
