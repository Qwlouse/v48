---
supplementary: Supplementary:jun16-supp.pdf
title: Anytime Exploration for Multi-armed Bandits using Confidence Information
abstract: We introduce anytime Explore-m, a pure exploration problem for multi-armed
  bandits (MAB) that requires making a prediction of the top-m arms at every time
  step. Anytime Explore-m is more practical than fixed budget or fixed confidence
  formulations of the top-m problem, since many applications involve a finite, but
  unpredictable, budget. However, the development and analysis of anytime algorithms
  present many challenges. We propose AT-LUCB (AnyTime Lower and Upper Confidence
  Bound), the first nontrivial algorithm that provably solves anytime Explore-m. Our
  analysis shows that the sample complexity of AT-LUCB is competitive to anytime variants
  of existing algorithms. Moreover, our empirical evaluation on AT-LUCB shows that
  AT-LUCB performs as well as or better than state-of-the-art baseline methods for
  anytime Explore-m.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: jun16
month: 0
firstpage: 974
lastpage: 982
page: 974-982
sections: 
author:
- given: Kwang-Sung
  family: Jun
- given: Robert
  family: Nowak
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/jun16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
