---
supplementary: Supplementary:canevet16-supp.pdf
title: Importance Sampling Tree for Large-scale Empirical Expectation
abstract: 'We propose a tree-based procedure inspired by the Monte-Carlo Tree Search
  that dynamically modulates an importance-based sampling to prioritize computation,
  while getting unbiased estimates of weighted sums. We apply this generic method
  to learning on very large training sets, and to the evaluation of large-scale SVMs.
  The core idea is to reformulate the estimation of a score - whether a loss or a
  prediction estimate - as an empirical expectation, and to use such a tree whose
  leaves carry the samples to focus efforts over the problematic "heavy weight" ones.
  We illustrate the potential of this approach on three problems: to improve Adaboost
  and a multi-layer perceptron on 2D synthetic tasks with several million points,
  to train a large-scale convolution network on several millions deformations of the
  CIFAR data-set, and to compute the response of a SVM with several hundreds of thousands
  of support vectors. In each case, we show how it either cuts down computation by
  more than one order of magnitude and/or allows to get better loss estimates.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: canevet16
month: 0
firstpage: 1454
lastpage: 1462
page: 1454-1462
sections: 
author:
- given: Olivier
  family: Canevet
- given: Cijo
  family: Jose
- given: Francois
  family: Fleuret
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/canevet16/canevet16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
