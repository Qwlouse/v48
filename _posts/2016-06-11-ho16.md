---
supplementary: Supplementary:ho16-supp.pdf
title: Model-Free Imitation Learning with Policy Optimization
abstract: In imitation learning, an agent learns how to behave in an environment with
  an unknown cost function by mimicking expert demonstrations. Existing imitation
  learning algorithms typically involve solving a sequence of planning or reinforcement
  learning problems. Such algorithms are therefore not directly applicable to large,
  high-dimensional environments, and their performance can significantly degrade if
  the planning problems are not solved to optimality. Under the apprenticeship learning
  formalism, we develop alternative model-free algorithms for finding a parameterized
  stochastic policy that performs at least as well as an expert policy on an unknown
  cost function, based on sample trajectories from the expert. Our approach, based
  on policy gradients, scales to large continuous environments with guaranteed convergence
  to local minima.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: ho16
month: 0
tex_title: Model-Free Imitation Learning with Policy Optimization
firstpage: 2760
lastpage: 2769
page: 2760-2769
sections: 
author:
- given: Jonathan
  family: Ho
- given: Jayesh
  family: Gupta
- given: Stefano
  family: Ermon
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/ho16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
