---
title: 'Cumulative Prospect Theory Meets Reinforcement Learning: Prediction and Control'
abstract: 'Cumulative prospect theory (CPT) is known to model human decisions well,
  with substantial empirical evidence supporting this claim. CPT works by distorting
  probabilities and is more general than the classic expected utility and coherent
  risk measures. We bring this idea to a risk-sensitive reinforcement learning (RL)
  setting and design algorithms for both estimation and control. The RL setting presents
  two particular challenges when CPT is applied: estimating the CPT objective requires
  estimations of the entire distribution of the value function and finding a randomized
  optimal policy. The estimation scheme that we propose uses the empirical distribution
  to estimate the CPT-value of a random variable. We then use this scheme in the inner
  loop of a CPT-value optimization procedure that is based on the well-known simulation
  optimization idea of simultaneous perturbation stochastic approximation (SPSA).
  We provide theoretical convergence guarantees for all the proposed algorithms and
  also empirically demonstrate the usefulness of our algorithms.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: la16
month: 0
tex_title: 'Cumulative Prospect Theory Meets Reinforcement Learning: Prediction and
  Control'
firstpage: 1406
lastpage: 1415
page: 1406-1415
order: 1406
cycles: false
author:
- given: Prashanth
  family: L.A.
- given: Cheng
  family: Jie
- given: Michael
  family: Fu
- given: Steve
  family: Marcus
- given: Csaba
  family: Szepesvari
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/la16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
