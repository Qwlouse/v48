---
title: SDCA without Duality, Regularization, and Individual Convexity
abstract: Stochastic Dual Coordinate Ascent is a popular method for solving regularized
  loss minimization for the case of convex losses. We describe variants of SDCA that
  do not require explicit regularization and do not rely on duality. We prove linear
  convergence rates even if individual loss functions are non-convex, as long as the
  expected loss is strongly convex.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: shalev-shwartza16
month: 0
firstpage: 747
lastpage: 754
page: 747-754
sections: 
author:
- given: Shai
  family: Shalev-Shwartz
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/shalev-shwartza16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
