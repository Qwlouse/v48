---
supplementary: http://proceedings.mlr.press/v48/curtis16-supp.pdf
title: A Self-Correcting Variable-Metric Algorithm for Stochastic Optimization
abstract: An algorithm for stochastic (convex or nonconvex) optimization is presented.
  The algorithm is variable-metric in the sense that, in each iteration, the step
  is computed through the product of a symmetric positive definite scaling matrix
  and a stochastic (mini-batch) gradient of the objective function, where the sequence
  of scaling matrices is updated dynamically by the algorithm. A key feature of the
  algorithm is that it does not overly restrict the manner in which the scaling matrices
  are updated. Rather, the algorithm exploits fundamental self-correcting properties
  of BFGS-type updatingâ€”properties that have been over-looked in other attempts to
  devise quasi-Newton methods for stochastic optimization. Numerical experiments illustrate
  that the method and a limited memory variant of it are stable and outperform (mini-batch)
  stochastic gradient and other quasi-Newton methods when employed to solve a few
  machine learning problems.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: curtis16
month: 0
tex_title: A Self-Correcting Variable-Metric Algorithm for Stochastic Optimization
firstpage: 632
lastpage: 641
page: 632-641
order: 632
cycles: false
author:
- given: Frank
  family: Curtis
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/curtis16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
