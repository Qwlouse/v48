<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>A Distributed Variational Inference Framework for Unifying Parallel Sparse Gaussian Process Regression Models | ICML 2016 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="A Distributed Variational Inference Framework for Unifying Parallel Sparse Gaussian Process Regression Models">

  <meta name="citation_author" content="Hoang, Trong Nghia">

  <meta name="citation_author" content="Hoang, Quang Minh">

  <meta name="citation_author" content="Low, Bryan Kian Hsiang">

<meta name="citation_publication_date" content="2016">
<meta name="citation_conference_title" content="Proceedings of The 33rd International Conference on Machine Learning">
<meta name="citation_firstpage" content="382">
<meta name="citation_lastpage" content="391">
<meta name="citation_pdf_url" content="http://jmlr.org/proceedings/papers/v48/hoang16.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>A Distributed Variational Inference Framework for Unifying Parallel Sparse Gaussian Process Regression Models</h1>

	<div id="authors">
	
		Trong Nghia Hoang,
	
		Quang Minh Hoang,
	
		Bryan Kian Hsiang Low
	<br />
	</div>
	<div id="info">
		Proceedings of The 33rd International Conference on Machine Learning,
		pp. 382â€“391, 2016
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		This paper presents a novel distributed variational inference framework that unifies many parallel sparse Gaussian process regression (SGPR) models for scalable hyperparameter learning with big data. To achieve this, our framework exploits a structure of correlated noise process model that represents the observation noises as a finite realization of a high-order Gaussian Markov random process. By varying the Markov order and covariance function for the noise process model, different variational SGPR models result. This consequently allows the correlation structure of the noise process model to be characterized for which a particular variational SGPR model is optimal. We empirically evaluate the predictive performance and scalability of the distributed variational SGPR models unified by our framework on two real-world datasets.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="hoang16.pdf">Download PDF</a></li>
			
			<li><a href="hoang16-supp.pdf">Supplementary (PDF)</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
