---
title: Provable Algorithms for Inference in Topic Models
abstract: Recently, there has been considerable progress on designing algorithms with
  provable guarantees —typically using linear algebraic methods—for parameter learning
  in latent variable models. Designing provable algorithms for inference has proved
  more difficult. Here we take a first step towards provable inference in topic models.
  We leverage a property of topic models that enables us to construct simple linear
  estimators for the unknown topic proportions that have small variance, and consequently
  can work with short documents. Our estimators also correspond to finding an estimate
  around which the posterior is well-concentrated. We show lower bounds that for shorter
  documents it can be information theoretically impossible to find the hidden topics.
  Finally, we give empirical results that demonstrate that our algorithm works on
  realistic topic models. It yields good solutions on synthetic data and runs in time
  comparable to a single iteration of Gibbs sampling.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: arorab16
month: 0
firstpage: 2859
lastpage: 2867
page: 2859-2867
sections: 
author:
- given: Sanjeev
  family: Arora
- given: Rong
  family: Ge
- given: Frederic
  family: Koehler
- given: Tengyu
  family: Ma
- given: Ankur
  family: Moitra
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/arorab16/arorab16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
