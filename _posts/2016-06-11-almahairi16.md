---
title: Dynamic Capacity Networks
abstract: 'We introduce the Dynamic Capacity Network (DCN), a neural network that
  can adaptively assign its capacity across different portions of the input data.
  This is achieved by combining modules of two types: low-capacity sub-networks and
  high-capacity sub-networks. The low-capacity sub-networks are applied across most
  of the input, but also provide a guide to select a few portions of the input on
  which to apply the high-capacity sub-networks. The selection is made using a novel
  gradient-based attention mechanism, that efficiently identifies input regions for
  which the DCNâ€™s output is most sensitive and to which we should devote more capacity.
  We focus our empirical evaluation on the Cluttered MNIST and SVHN image datasets.
  Our findings indicate that DCNs are able to drastically reduce the number of computations,
  compared to traditional convolutional neural networks, while maintaining similar
  or even better performance.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: almahairi16
month: 0
tex_title: Dynamic Capacity Networks
firstpage: 2549
lastpage: 2558
page: 2549-2558
order: 2549
cycles: false
author:
- given: Amjad
  family: Almahairi
- given: Nicolas
  family: Ballas
- given: Tim
  family: Cooijmans
- given: Yin
  family: Zheng
- given: Hugo
  family: Larochelle
- given: Aaron
  family: Courville
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/almahairi16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
