<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Gaussian quadrature for matrix inverse forms with applications | ICML 2016 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Gaussian quadrature for matrix inverse forms with applications">

  <meta name="citation_author" content="Li, Chengtao">

  <meta name="citation_author" content="Sra, Suvrit">

  <meta name="citation_author" content="Jegelka, Stefanie">

<meta name="citation_publication_date" content="2016">
<meta name="citation_conference_title" content="Proceedings of The 33rd International Conference on Machine Learning">
<meta name="citation_firstpage" content="1766">
<meta name="citation_lastpage" content="1775">
<meta name="citation_pdf_url" content="http://jmlr.org/proceedings/papers/v48/lig16.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Gaussian quadrature for matrix inverse forms with applications</h1>

	<div id="authors">
	
		Chengtao Li,
	
		Suvrit Sra,
	
		Stefanie Jegelka
	<br />
	</div>
	<div id="info">
		Proceedings of The 33rd International Conference on Machine Learning,
		pp. 1766â€“1775, 2016
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		We present a framework for accelerating a spectrum of machine learning algorithms that require computation of <em>bilinear inverse forms</em> <span class="math">\(u^T A^{-1}u\)</span>, where <span class="math">\(A\)</span> is a positive definite matrix and <span class="math">\(u\)</span> a given vector. Our framework is built on Gauss-type quadrature and easily scales to large, sparse matrices. Further, it allows retrospective computation of lower and upper bounds on <span class="math">\(u^T A^{-1}u\)</span>, which in turn accelerates several algorithms. We prove that these bounds tighten iteratively and converge at a linear (geometric) rate. To our knowledge, ours is the first work to demonstrate these key properties of Gauss-type quadrature, which is a classical and deeply studied topic. We illustrate empirical consequences of our results by using quadrature to accelerate machine learning tasks involving determinantal point processes and submodular optimization, and observe tremendous speedups in several instances.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="lig16.pdf">Download PDF</a></li>
			
			<li><a href="lig16-supp.pdf">Supplementary (PDF)</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
