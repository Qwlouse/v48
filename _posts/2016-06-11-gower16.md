---
title: 'Stochastic Block BFGS: Squeezing More Curvature out of Data'
abstract: We propose a novel limited-memory stochastic block BFGS update for incorporating
  enriched curvature information in stochastic approximation methods. In our method,
  the estimate of the inverse Hessian matrix that is maintained by it, is updated
  at each iteration using a sketch of the Hessian, i.e., a randomly generated compressed
  form of the Hessian. We propose several sketching strategies, present a new quasi-Newton
  method that uses stochastic block BFGS updates combined with the variance reduction
  approach SVRG to compute batch stochastic gradients, and prove linear convergence
  of the resulting method. Numerical tests on large-scale logistic regression problems
  reveal that our method is more robust and substantially outperforms current state-of-the-art
  methods.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: gower16
month: 0
firstpage: 1869
lastpage: 1878
page: 1869-1878
sections: 
author:
- given: Robert
  family: Gower
- given: Donald
  family: Goldfarb
- given: Peter
  family: Richtarik
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/gower16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
