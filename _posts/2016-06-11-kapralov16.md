---
supplementary: http://proceedings.mlr.press/v48/kapralov16-supp.pdf
title: How to Fake Multiply by a Gaussian Matrix
abstract: Have you ever wanted to multiply an n \times d matrix X, with n ≫d, on the
  left by an m \times n matrix \tilde G of i.i.d. Gaussian random variables, but could
  not afford to do it because it was too slow? In this work we propose a new randomized
  m \times n matrix T, for which one can compute T ⋅X in only O(nnz(X)) + \tilde O(m^1.5
  ⋅d^3) time, for which the total variation distance between the distributions T ⋅X
  and \tilde G ⋅X is as small as desired, i.e., less than any positive constant. Here
  nnz(X) denotes the number of non-zero entries of X. Assuming nnz(X) ≫m^1.5 ⋅d^3,
  this is a significant savings over the naïve O(nnz(X) m) time to compute \tilde
  G ⋅X. Moreover, since the total variation distance is small, we can provably use
  T ⋅X in place of \tilde G ⋅X in any application and have the same guarantees as
  if we were using \tilde G ⋅X, up to a small positive constant in error probability.
  We apply this transform to nonnegative matrix factorization (NMF) and support vector
  machines (SVM).
layout: inproceedings
series: Proceedings of Machine Learning Research
id: kapralov16
month: 0
tex_title: How to Fake Multiply by a Gaussian Matrix
firstpage: 2101
lastpage: 2110
page: 2101-2110
order: 2101
cycles: false
author:
- given: Michael
  family: Kapralov
- given: Vamsi
  family: Potluru
- given: David
  family: Woodruff
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/kapralov16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
