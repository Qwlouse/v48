---
supplementary: Supplementary:arjevani16-supp.pdf
title: On the Iteration Complexity of Oblivious First-Order Optimization Algorithms
abstract: We consider a broad class of first-order optimization algorithms which are
  \emphoblivious, in the sense that their step sizes are scheduled regardless of the
  function under consideration, except for limited side-information such as smoothness
  or strong convexity parameters. With the knowledge of these two parameters, we show
  that any such algorithm attains an iteration complexity lower bound of Ω(\sqrtL/ε)
  for L-smooth convex functions, and \tildeΩ(\sqrtL/μ\ln(1/ε)) for L-smooth μ-strongly
  convex functions. These lower bounds are stronger than those in the traditional
  oracle model, as they hold independently of the dimension. To attain these, we abandon
  the oracle model in favor of a structure-based approach which builds upon a framework
  recently proposed in Arjevani et al. (2015). We further show that without knowing
  the strong convexity parameter, it is impossible to attain an iteration complexity
  better than \tildeΩ\sqrt(L/μ)\ln(1/ε). This result is then used to formalize an
  observation regarding L-smooth convex functions, namely, that the iteration complexity
  of algorithms employing time-invariant step sizes must be at least Ω(L/ε).
layout: inproceedings
series: Proceedings of Machine Learning Research
id: arjevani16
month: 0
firstpage: 908
lastpage: 916
page: 908-916
sections: 
author:
- given: Yossi
  family: Arjevani
- given: Ohad
  family: Shamir
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/arjevani16/arjevani16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
