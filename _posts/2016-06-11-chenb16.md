---
supplementary: Supplementary:chenb16-supp.pdf
title: Scalable Discrete Sampling as a Multi-Armed Bandit Problem
abstract: Drawing a sample from a discrete distribution is one of the building components
  for Monte Carlo methods. Like other sampling algorithms, discrete sampling suffers
  from the high computational burden in large-scale inference problems. We study the
  problem of sampling a discrete random variable with a high degree of dependency
  that is typical in large-scale Bayesian inference and graphical models, and propose
  an efficient approximate solution with a subsampling approach. We make a novel connection
  between the discrete sampling and Multi-Armed Bandits problems with a finite reward
  population and provide three algorithms with theoretical guarantees. Empirical evaluations
  show the robustness and efficiency of the approximate algorithms in both synthetic
  and real-world large-scale problems.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: chenb16
month: 0
firstpage: 2492
lastpage: 2501
page: 2492-2501
sections: 
author:
- given: Yutian
  family: Chen
- given: Zoubin
  family: Ghahramani
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/chenb16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
