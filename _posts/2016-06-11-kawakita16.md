---
supplementary: Supplementary:kawakita16-supp.pdf
title: Barron and Cover's Theory in Supervised Learning and its Application to Lasso
abstract: We study Barron and Cover’s theory (BC theory) in supervised learning. The
  original BC theory can be applied to supervised learning only approximately and
  limitedly. Though Barron (2008) and Chatterjee and Barron (2014) succeeded in removing
  the approximation, their idea cannot be essentially applied to supervised learning
  in general. By solving this issue, we propose an extension of BC theory to supervised
  learning. The extended theory has several advantages inherited from the original
  BC theory. First, it holds for finite sample number n. Second, it requires remarkably
  few assumptions. Third, it gives a justification of the MDL principle in supervised
  learning. We also derive new risk and regret bounds of lasso with random design
  as its application. The derived risk bound hold for any finite n without boundedness
  of features in contrast to past work. Behavior of the regret bound is investigated
  by numerical simulations. We believe that this is the first extension of BC theory
  to general supervised learning without approximation.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: kawakita16
month: 0
firstpage: 1958
lastpage: 1966
page: 1958-1966
sections: 
author:
- given: Masanori
  family: Kawakita
- given: Jun’ichi
  family: Takeuchi
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/kawakita16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
