<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Online Stochastic Linear Optimization under One-bit Feedback | ICML 2016 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Online Stochastic Linear Optimization under One-bit Feedback">

  <meta name="citation_author" content="Zhang, Lijun">

  <meta name="citation_author" content="Yang, Tianbao">

  <meta name="citation_author" content="Jin, Rong">

  <meta name="citation_author" content="Xiao, Yichi">

  <meta name="citation_author" content="Zhou, Zhi-hua">

<meta name="citation_publication_date" content="2016">
<meta name="citation_conference_title" content="Proceedings of The 33rd International Conference on Machine Learning">
<meta name="citation_firstpage" content="392">
<meta name="citation_lastpage" content="401">
<meta name="citation_pdf_url" content="http://jmlr.org/proceedings/papers/v48/zhangb16.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Online Stochastic Linear Optimization under One-bit Feedback</h1>

	<div id="authors">
	
		Lijun Zhang,
	
		Tianbao Yang,
	
		Rong Jin,
	
		Yichi Xiao,
	
		Zhi-hua Zhou
	<br />
	</div>
	<div id="info">
		Proceedings of The 33rd International Conference on Machine Learning,
		pp. 392â€“401, 2016
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		In this paper, we study a special bandit setting of online stochastic linear optimization, where only one-bit of information is revealed to the learner at each round. This problem has found many applications including online advertisement and online recommendation. We assume the binary feedback is a random variable generated from the logit model, and aim to minimize the regret defined by the unknown linear function. Although the existing method for generalized linear bandit can be applied to our problem, the high computational cost makes it impractical for real-world applications. To address this challenge, we develop an efficient online learning algorithm by exploiting particular structures of the observation model. Specifically, we adopt online Newton step to estimate the unknown parameter and derive a tight confidence region based on the exponential concavity of the logistic loss. Our analysis shows that the proposed algorithm achieves a regret bound of <span class="math">\(O(d\sqrt{T})\)</span>, which matches the optimal result of stochastic linear bandits.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="zhangb16.pdf">Download PDF</a></li>
			
			<li><a href="zhangb16-supp.pdf">Supplementary (PDF)</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
