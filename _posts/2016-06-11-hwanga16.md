---
supplementary: Supplementary:hwanga16-supp.pdf
title: Sequence to Sequence Training of CTC-RNNs with Partial Windowing
abstract: Connectionist temporal classification (CTC) based supervised sequence training
  of recurrent neural networks (RNNs) has shown great success in many machine learning
  areas including end-to-end speech and handwritten character recognition. For the
  CTC training, however, it is required to unroll (or unfold) the RNN by the length
  of an input sequence. This unrolling requires a lot of memory and hinders a small
  footprint implementation of online learning or adaptation. Furthermore, the length
  of training sequences is usually not uniform, which makes parallel training with
  multiple sequences inefficient on shared memory models such as graphics processing
  units (GPUs). In this work, we introduce an expectation-maximization (EM) based
  online CTC algorithm that enables unidirectional RNNs to learn sequences that are
  longer than the amount of unrolling. The RNNs can also be trained to process an
  infinitely long input sequence without pre-segmentation or external reset. Moreover,
  the proposed approach allows efficient parallel training on GPUs. Our approach achieves
  20.7% phoneme error rate (PER) on the very long input sequence that is generated
  by concatenating all 192 utterances in the TIMIT core test set. In the end-to-end
  speech recognition task on the Wall Street Journal corpus, a network can be trained
  with only 64 times of unrolling with little performance loss.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: hwanga16
month: 0
firstpage: 2178
lastpage: 2187
page: 2178-2187
sections: 
author:
- given: Kyuyeon
  family: Hwang
- given: Wonyong
  family: Sung
date: 2016-06-11
address: New York, New York, USA
publisher: PMLR
container-title: Proceedings of The 33rd International Conference on Machine Learning
volume: '48'
genre: inproceedings
issued:
  date-parts:
  - 2016
  - 6
  - 11
pdf: http://proceedings.mlr.press/v48/hwanga16.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
