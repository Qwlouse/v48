<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<title>Non-negative Matrix Factorization under Heavy Noise | ICML 2016 | JMLR W&amp;CP</title>

	<!-- Stylesheet -->
	<link rel="stylesheet" type="text/css" href="../css/jmlr.css" />

	<!-- Fixed position navigation -->
	<!--#include virtual="/proceedings/css-scroll.txt"-->

	<!-- MathJax -->
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(','\\)']]}});
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


	<!-- Metadata -->
	<!-- Google Scholar Meta Data -->

<meta name="citation_title" content="Non-negative Matrix Factorization under Heavy Noise">

  <meta name="citation_author" content="Bhattacharya, Chiranjib">

  <meta name="citation_author" content="Goyal, Navin">

  <meta name="citation_author" content="Kannan, Ravindran">

  <meta name="citation_author" content="Pani, Jagdeep">

<meta name="citation_publication_date" content="2016">
<meta name="citation_conference_title" content="Proceedings of The 33rd International Conference on Machine Learning">
<meta name="citation_firstpage" content="1426">
<meta name="citation_lastpage" content="1434">
<meta name="citation_pdf_url" content="http://jmlr.org/proceedings/papers/v48/bhattacharya16.pdf">

</head>
<body>


<div id="fixed">
<!--#include virtual="/proceedings/nav-bar.txt"-->
</div>

<div id="content">

	<h1>Non-negative Matrix Factorization under Heavy Noise</h1>

	<div id="authors">
	
		Chiranjib Bhattacharya,
	
		Navin Goyal,
	
		Ravindran Kannan,
	
		Jagdeep Pani
	<br />
	</div>
	<div id="info">
		Proceedings of The 33rd International Conference on Machine Learning,
		pp. 1426–1434, 2016
	</div> <!-- info -->

	

	<h2>Abstract</h2>
	<div id="abstract">
		The Noisy Non-negative Matrix factorization (NMF) is: given a data matrix A (d x n), find non-negative matrices B;C (d x k, k x n respy.) so that A = BC +N, where N is a noise matrix. Existing polynomial time algorithms with proven error guarantees require EACH column <span class="math">\(N_{\cdot j}\)</span> to have l1 norm much smaller than <span class="math">\(||(BC)_{\cdot j} ||_1\)</span>, which could be very restrictive. In important applications of NMF such as Topic Modeling as well as theoretical noise models (e.g. Gaussian with high sigma), almost EVERY column of <span class="math">\(N_{.j}\)</span> violates this condition. We introduce the heavy noise model which only requires the average noise over large subsets of columns to be small. We initiate a study of Noisy NMF under the heavy noise model. We show that our noise model subsumes noise models of theoretical and practical interest (for e.g. Gaussian noise of maximum possible sigma). We then devise an algorithm TSVDNMF which under certain assumptions on B,C, solves the problem under heavy noise. Our error guarantees match those of previous algorithms. Our running time of <span class="math">\(O(k.(d+n)^2)\)</span> is substantially better than the <span class="math">\(O(d.n^3)\)</span> for the previous best. Our assumption on B is weaker than the “Separability” assumption made by all previous results. We provide empirical justification for our assumptions on C. We also provide the first proof of identifiability (uniqueness of B) for noisy NMF which is not based on separability and does not use hard to check geometric conditions. Our algorithm outperforms earlier polynomial time algorithms both in time and error, particularly in the presence of high noise.
	</div>

	<h2>Related Material</h2>
	<div id="extras">
		<ul>
			<li><a href="bhattacharya16.pdf">Download PDF</a></li>
			
			<li><a href="bhattacharya16-supp.pdf">Supplementary (PDF)</a></li>
			
			
		</ul>
	</div> <!-- extras -->

</div> <!-- content -->

</body>
</html>
